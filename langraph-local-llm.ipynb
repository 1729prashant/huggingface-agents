{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a080806-8a84-457f-9cc3-48f615442d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from typing import Annotated, Optional, TypedDict\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------\n",
    "# Tools\n",
    "# -------------------\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Simple calculator tool.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "def extract_text(img_path: str) -> str:\n",
    "    \"\"\"Extract text from image using pytesseract OCR.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading image: {e}\"\n",
    "\n",
    "# -------------------\n",
    "# Agent State\n",
    "# -------------------\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input_file: Optional[str]\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# -------------------\n",
    "# Models\n",
    "# -------------------\n",
    "\n",
    "# Local model: change if you have another Ollama model\n",
    "llm = ChatOllama(model=\"qwen2.5-coder:7b\")\n",
    "\n",
    "# Bind tools (enables ReAct pattern)\n",
    "# llm_with_tools = llm.bind_tools([divide, extract_text]), parallel_tool_calls=False)\n",
    "llm_with_tools = llm.bind_tools([divide, extract_text])\n",
    "\n",
    "# -------------------\n",
    "# Assistant Node\n",
    "# -------------------\n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    \"\"\"\n",
    "    Alfred the butler can analyze documents, call tools,\n",
    "    and reason over the extracted text.\n",
    "    \"\"\"\n",
    "    sys_msg = SystemMessage(\n",
    "        content=(\n",
    "            \"You are Alfred, a helpful butler who can analyze documents and call tools. \"\n",
    "            \"When extract_text returns text, read it carefully as if it were a document. \"\n",
    "            \"Then, follow the humanâ€™s request based on that extracted content. \"\n",
    "            \"For example, if asked to pick items, read the extracted text and select from it.\"\n",
    "        )\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])],\n",
    "        \"input_file\": state[\"input_file\"],\n",
    "    }\n",
    "\n",
    "\n",
    "#testing the text extract\n",
    "text = extract_text(\"menu.jpg\")\n",
    "print(\"================================ Debug Start =================================\")\n",
    "print(\"extract_text\")\n",
    "print(text)\n",
    "print(\"================================ Debug End   =================================\")\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Graph Setup\n",
    "# -------------------\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([divide, extract_text]))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# -------------------\n",
    "# Run Query\n",
    "# -------------------\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"From the provided image menu.jpeg, pick any three items you recommend.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "result = react_graph.invoke({\"messages\": messages, \"input_file\": \"menu.jpeg\"})\n",
    "\n",
    "# -------------------\n",
    "# Display Messages\n",
    "# -------------------\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
