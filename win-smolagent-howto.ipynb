{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1da61c-dbc7-499d-b017-7728ce96fe37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "#Login() calls an inbuilt login prompt that does not work for me\n",
    "#login()\n",
    "\n",
    "\n",
    "# Load environment variables from .env file in current directory\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "# Fetch the HuggingFace token\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# Verify token is loaded\n",
    "print(\"Token loaded:\", token is not None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2aaa8-afab-449b-b9f1-ac7905a99eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using smolagents, we can build an agent capable of searching the web using DuckDuckGo.\n",
    "# To give the agent access to this tool, we include it in the tool list when creating the agent.\n",
    "# For the model, we’ll rely on InferenceClientModel, which provides access to Hugging Face’s Serverless Inference API. \n",
    "# The default model is \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n",
    "\n",
    "\n",
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, InferenceClientModel\n",
    "\n",
    "agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=InferenceClientModel())\n",
    "\n",
    "agent.run(\"Search for the best music recommendations for a party at the Wayne's mansion.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dfbe4c-3364-4faf-a899-0ef8eb352d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, tool, InferenceClientModel\n",
    "\n",
    "# Tool to suggest a menu based on the occasion\n",
    "@tool\n",
    "def suggest_menu(occasion: str) -> str:\n",
    "    \"\"\"\n",
    "    Suggests a menu based on the occasion.\n",
    "    Args:\n",
    "        occasion (str): The type of occasion for the party. Allowed values are:\n",
    "                        - \"casual\": Menu for casual party.\n",
    "                        - \"formal\": Menu for formal party.\n",
    "                        - \"superhero\": Menu for superhero party.\n",
    "                        - \"custom\": Custom menu.\n",
    "    \"\"\"\n",
    "    if occasion == \"casual\":\n",
    "        return \"Pizza, snacks, and drinks.\"\n",
    "    elif occasion == \"formal\":\n",
    "        return \"3-course dinner with wine and dessert.\"\n",
    "    elif occasion == \"superhero\":\n",
    "        return \"Buffet with high-energy and healthy food.\"\n",
    "    else:\n",
    "        return \"Custom menu for the butler.\"\n",
    "\n",
    "# Alfred, the butler, preparing the menu for the party\n",
    "agent = CodeAgent(tools=[suggest_menu], model=InferenceClientModel())\n",
    "\n",
    "# Preparing the menu for the party\n",
    "agent.run(\"Prepare a formal menu for the party.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d9b60-f8d4-4aae-b271-b4c082692e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code execution has strict security measures - imports outside a predefined safe list are blocked by default. \n",
    "# However, you can authorize additional imports by passing them as strings in additional_authorized_imports. \n",
    "# For more details on secure code execution, see the official guide: https://huggingface.co/docs/smolagents/tutorials/secure_code_execution\n",
    "\n",
    "from smolagents import CodeAgent, InferenceClientModel\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "agent = CodeAgent(tools=[], model=InferenceClientModel(), additional_authorized_imports=['datetime'])\n",
    "\n",
    "agent.run(\n",
    "    \"\"\"\n",
    "    Alfred needs to prepare for the party. Here are the tasks:\n",
    "    1. Prepare the drinks - 30 minutes\n",
    "    2. Decorate the mansion - 60 minutes\n",
    "    3. Set up the menu - 45 minutes\n",
    "    4. Prepare the music and playlist - 45 minutes\n",
    "\n",
    "    If we start right now, at what time will the party be ready?\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa873c0b-19c2-4f53-b8f3-7071321e4372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The smolagents library makes this possible by allowing you to share a complete agent with the community and download others for immediate use. \n",
    "HUB_NAME = '1729prashant/AlfredAgent'\n",
    "agent.push_to_hub(HUB_NAME)\n",
    "\n",
    "# To download the agent again, use the code below:\n",
    "# Change to your username and repo name\n",
    "alfred_agent = agent.from_hub(HUB_NAME, trust_remote_code=True)\n",
    "\n",
    "alfred_agent.run(\"Give me the best playlist for a party at Wayne's mansion. The party idea is a 'villain masquerade' theme\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d292de-7f72-4256-ae6c-3d63406c2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did Alfred build such an agent using smolagents? By integrating several tools, he can generate an agent as follows. \n",
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, FinalAnswerTool, InferenceClientModel, Tool, tool, VisitWebpageTool\n",
    "\n",
    "@tool\n",
    "def suggest_menu(occasion: str) -> str:\n",
    "    \"\"\"\n",
    "    Suggests a menu based on the occasion.\n",
    "    Args:\n",
    "        occasion: The type of occasion for the party.\n",
    "    \"\"\"\n",
    "    if occasion == \"casual\":\n",
    "        return \"Pizza, snacks, and drinks.\"\n",
    "    elif occasion == \"formal\":\n",
    "        return \"3-course dinner with wine and dessert.\"\n",
    "    elif occasion == \"superhero\":\n",
    "        return \"Buffet with high-energy and healthy food.\"\n",
    "    else:\n",
    "        return \"Custom menu for the butler.\"\n",
    "\n",
    "@tool\n",
    "def catering_service_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool returns the highest-rated catering service in Gotham City.\n",
    "    \n",
    "    Args:\n",
    "        query: A search term for finding catering services.\n",
    "    \"\"\"\n",
    "    # Example list of catering services and their ratings\n",
    "    services = {\n",
    "        \"Gotham Catering Co.\": 4.9,\n",
    "        \"Wayne Manor Catering\": 4.8,\n",
    "        \"Gotham City Events\": 4.7,\n",
    "    }\n",
    "    \n",
    "    # Find the highest rated catering service (simulating search query filtering)\n",
    "    best_service = max(services, key=services.get)\n",
    "    \n",
    "    return best_service\n",
    "\n",
    "class SuperheroPartyThemeTool(Tool):\n",
    "    name = \"superhero_party_theme_generator\"\n",
    "    description = \"\"\"\n",
    "    This tool suggests creative superhero-themed party ideas based on a category.\n",
    "    It returns a unique party theme idea.\"\"\"\n",
    "    \n",
    "    inputs = {\n",
    "        \"category\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The type of superhero party (e.g., 'classic heroes', 'villain masquerade', 'futuristic Gotham').\",\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    output_type = \"string\"\n",
    "\n",
    "    def forward(self, category: str):\n",
    "        themes = {\n",
    "            \"classic heroes\": \"Justice League Gala: Guests come dressed as their favorite DC heroes with themed cocktails like 'The Kryptonite Punch'.\",\n",
    "            \"villain masquerade\": \"Gotham Rogues' Ball: A mysterious masquerade where guests dress as classic Batman villains.\",\n",
    "            \"futuristic Gotham\": \"Neo-Gotham Night: A cyberpunk-style party inspired by Batman Beyond, with neon decorations and futuristic gadgets.\"\n",
    "        }\n",
    "        \n",
    "        return themes.get(category.lower(), \"Themed party idea not found. Try 'classic heroes', 'villain masquerade', or 'futuristic Gotham'.\")\n",
    "\n",
    "\n",
    "# Alfred, the butler, preparing the menu for the party\n",
    "agent = CodeAgent(\n",
    "    tools=[\n",
    "        DuckDuckGoSearchTool(), \n",
    "        VisitWebpageTool(),\n",
    "        suggest_menu,\n",
    "        catering_service_tool,\n",
    "        SuperheroPartyThemeTool(),\n",
    "\tFinalAnswerTool()\n",
    "    ], \n",
    "    model=InferenceClientModel(),\n",
    "    max_steps=10,\n",
    "    verbosity_level=2\n",
    ")\n",
    "\n",
    "agent.run(\"Give me the best playlist for a party at the Wayne's mansion. The party idea is a 'villain masquerade' theme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f73609-592d-4c21-b655-1ff210c822bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Alfred fine-tunes the Party Preparator Agent, he’s growing weary of debugging its runs. \n",
    "# Agents, by nature, are unpredictable and difficult to inspect. But since he aims to build \n",
    "# the ultimate Party Preparator Agent and deploy it in production, he needs robust traceability \n",
    "# for future monitoring and analysis.\n",
    "\n",
    "# Once again, smolagents comes to the rescue! It embraces the OpenTelemetry standard for \n",
    "# instrumenting agent runs, allowing seamless inspection and logging. With the help of Langfuse \n",
    "# and the SmolagentsInstrumentor, Alfred can easily track and analyze his agent’s behavior.\n",
    "\n",
    "# First, we need to install the necessary dependencies:\n",
    "!pip install opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-smolagents langfuse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0864359-a596-4f53-bc96-5398ec143cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, Alfred has already created an account on Langfuse and has his API keys ready. \n",
    "# If you haven’t done so yet, you can sign up for Langfuse Cloud here https://cloud.langfuse.com/ \n",
    "# or explore alternatives https://huggingface.co/docs/smolagents/tutorials/inspect_runs\n",
    "\n",
    "# Once you have your API keys, they need to be properly configured as follows:\n",
    "import os\n",
    "\n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # 🇪🇺 EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # 🇺🇸 US region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b71c15-293a-4987-b6ea-d603667ae2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the environment variables set, we can now initialize the Langfuse client. \n",
    "# get_client() initializes the Langfuse client using the credentials provided in the environment variables.\n",
    "\n",
    "from langfuse import get_client\n",
    " \n",
    "langfuse = get_client()\n",
    " \n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")\n",
    "\n",
    "\n",
    "# Finally, Alfred is ready to initialize the SmolagentsInstrumentor and start tracking his agent’s performance.\n",
    "\n",
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    "\n",
    "SmolagentsInstrumentor().instrument()\n",
    "\n",
    "\n",
    "from smolagents import CodeAgent, InferenceClientModel\n",
    "\n",
    "agent = CodeAgent(tools=[], model=InferenceClientModel())\n",
    "alfred_agent = agent.from_hub('sergiopaniego/AlfredAgent', trust_remote_code=True)\n",
    "alfred_agent.run(\"Give me the best playlist for a party at Wayne's mansion. The party idea is a 'villain masquerade' theme\")  \n",
    "\n",
    "# Alfred can now access these logs here https://cloud.langfuse.com/project/cm7bq0abj025rad078ak3luwi/traces/995fc019255528e4f48cf6770b0ce27b?timestamp=2025-02-19T10%3A28%3A36.929Z\n",
    "# to review and analyze them.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d3660-03f0-49a5-ae0b-37ffa1b5d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import smolagents\n",
    "#print(inspect.getsourcefile(smolagents.DuckDuckGoSearchTool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540c9cf-345f-46a1-8416-981f9dc8dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Example: Running a Tool Calling Agent\n",
    "\n",
    "from smolagents import ToolCallingAgent, DuckDuckGoSearchTool, InferenceClientModel\n",
    "\n",
    "agent = ToolCallingAgent(tools=[DuckDuckGoSearchTool()], model=InferenceClientModel())\n",
    "\n",
    "agent.run(\"Search for the best music recommendations for a party at the Wayne's mansion.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a3ed7-a216-4ca8-8d71-c8505919be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In smolagents, tools are treated as functions that an LLM can call within an agent system.\n",
    "\n",
    "# To interact with a tool, the LLM needs an interface description with these key components:\n",
    "\n",
    "#    Name: What the tool is called\n",
    "#    Tool description: What the tool does\n",
    "#    Input types and descriptions: What arguments the tool accepts\n",
    "#    Output type: What the tool returns\n",
    "\n",
    "# For instance, while preparing for a party at Wayne Manor, Alfred needs various tools to gather information - \n",
    "# from searching for catering services to finding party theme ideas. Here’s how a simple search tool interface might look:\n",
    "\n",
    "#    Name: web_search\n",
    "#    Tool description: Searches the web for specific queries\n",
    "#    Input: query (string) - The search term to look up\n",
    "#    Output: String containing the search results\n",
    "\n",
    "# By using these tools, Alfred can make informed decisions and gather all the information needed for planning the perfect party.\n",
    "\n",
    "\n",
    "# Tool Creation Methods\n",
    "\n",
    "# In smolagents, tools can be defined in two ways:\n",
    "#    Using the @tool decorator for simple function-based tools\n",
    "#    Creating a subclass of Tool for more complex functionality\n",
    "\n",
    "# The @tool Decorator\n",
    "# The @tool decorator is the recommended way to define simple tools. Under the hood, \n",
    "# smolagents will parse basic information about the function from Python. So if you name \n",
    "# your function clearly and write a good docstring, it will be easier for the LLM to use.\n",
    "\n",
    "# Using this approach, we define a function with:\n",
    "#    A clear and descriptive function name that helps the LLM understand its purpose.\n",
    "#    Type hints for both inputs and outputs to ensure proper usage.\n",
    "#    A detailed description, including an Args: section where each argument is explicitly described. \n",
    "#    - These descriptions provide valuable context for the LLM, so it’s important to write them carefully.\n",
    "\n",
    "\n",
    "# Below is an example of how Alfred can use the @tool decorator to make this happen:\n",
    "\n",
    "from smolagents import CodeAgent, InferenceClientModel, tool\n",
    "\n",
    "# Let's pretend we have a function that fetches the highest-rated catering services.\n",
    "@tool\n",
    "def catering_service_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool returns the highest-rated catering service in Gotham City.\n",
    "\n",
    "    Args:\n",
    "        query: A search term for finding catering services.\n",
    "    \"\"\"\n",
    "    # Example list of catering services and their ratings\n",
    "    services = {\n",
    "        \"Gotham Catering Co.\": 4.9,\n",
    "        \"Wayne Manor Catering\": 4.8,\n",
    "        \"Gotham City Events\": 4.7,\n",
    "    }\n",
    "\n",
    "    # Find the highest rated catering service (simulating search query filtering)\n",
    "    best_service = max(services, key=services.get)\n",
    "\n",
    "    return best_service\n",
    "\n",
    "\n",
    "agent = CodeAgent(tools=[catering_service_tool], model=InferenceClientModel())\n",
    "\n",
    "# Run the agent to find the best catering service\n",
    "result = agent.run(\"Can you give me the name of the highest-rated catering service in Gotham City?\")\n",
    "\n",
    "print(result)   # Output: Gotham Catering Co.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Defining a Tool as a Python Class\n",
    "\n",
    "# This approach involves creating a subclass of Tool. For complex tools, we can implement a class instead of a Python function. \n",
    "# The class wraps the function with metadata that helps the LLM understand how to use it effectively. In this class, we define:\n",
    "#    name: The tool’s name.\n",
    "#    description: A description used to populate the agent’s system prompt.\n",
    "#    inputs: A dictionary with keys type and description, providing information to help the Python interpreter process inputs.\n",
    "#    output_type: Specifies the expected output type.\n",
    "#    forward: The method containing the inference logic to execute.\n",
    "\n",
    "#Below, we can see an example of a tool built using Tool and how to integrate it within a CodeAgent.\n",
    "#Generating a tool to generate ideas about the superhero-themed party\n",
    "\n",
    "# Alfred’s party at the mansion is a superhero-themed event, but he needs some creative ideas to make it truly special. \n",
    "# As a fantastic host, he wants to surprise the guests with a unique theme.\n",
    "\n",
    "# To do this, he can use an agent that generates superhero-themed party ideas based on a given category. \n",
    "# This way, Alfred can find the perfect party theme to wow his guests.\n",
    "\n",
    "\n",
    "\n",
    "from smolagents import Tool, CodeAgent, InferenceClientModel\n",
    "\n",
    "class SuperheroPartyThemeTool(Tool):\n",
    "    name = \"superhero_party_theme_generator\"\n",
    "    description = \"\"\"\n",
    "    This tool suggests creative superhero-themed party ideas based on a category.\n",
    "    It returns a unique party theme idea.\"\"\"\n",
    "\n",
    "    inputs = {\n",
    "        \"category\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The type of superhero party (e.g., 'classic heroes', 'villain masquerade', 'futuristic Gotham').\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def forward(self, category: str):\n",
    "        themes = {\n",
    "            \"classic heroes\": \"Justice League Gala: Guests come dressed as their favorite DC heroes with themed cocktails like 'The Kryptonite Punch'.\",\n",
    "            \"villain masquerade\": \"Gotham Rogues' Ball: A mysterious masquerade where guests dress as classic Batman villains.\",\n",
    "            \"futuristic Gotham\": \"Neo-Gotham Night: A cyberpunk-style party inspired by Batman Beyond, with neon decorations and futuristic gadgets.\"\n",
    "        }\n",
    "\n",
    "        return themes.get(category.lower(), \"Themed party idea not found. Try 'classic heroes', 'villain masquerade', or 'futuristic Gotham'.\")\n",
    "\n",
    "# Instantiate the tool\n",
    "party_theme_tool = SuperheroPartyThemeTool()\n",
    "agent = CodeAgent(tools=[party_theme_tool], model=InferenceClientModel())\n",
    "\n",
    "# Run the agent to generate a party theme idea\n",
    "result = agent.run(\n",
    "    \"What would be a good superhero party idea for a 'villain masquerade' theme?\"\n",
    ")\n",
    "\n",
    "print(result)  # Output: \"Gotham Rogues' Ball: A mysterious masquerade where guests dress as classic Batman villains.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# smolagents comes with a set of pre-built tools that can be directly injected into your agent. The default toolbox includes:\n",
    "#    PythonInterpreterTool\n",
    "#    FinalAnswerTool\n",
    "#    UserInputTool\n",
    "#    DuckDuckGoSearchTool\n",
    "#    GoogleSearchTool\n",
    "#    VisitWebpageTool\n",
    "\n",
    "# Alfred could use various tools to ensure a flawless party at Wayne Manor:\n",
    "#    First, he could use the DuckDuckGoSearchTool to find creative superhero-themed party ideas.\n",
    "#    For catering, he’d rely on the GoogleSearchTool to find the highest-rated services in Gotham.\n",
    "#    To manage seating arrangements, Alfred could run calculations with the PythonInterpreterTool.\n",
    "#    Once everything is gathered, he’d compile the plan using the FinalAnswerTool.\n",
    "# With these tools, Alfred guarantees the party is both exceptional and seamless. \n",
    "\n",
    "\n",
    "# Sharing and Importing Tools\n",
    "# One of the most powerful features of smolagents is its ability to share custom tools on the Hub \n",
    "# and seamlessly integrate tools created by the community. This includes connecting with HF Spaces \n",
    "# and LangChain tools, significantly enhancing Alfred’s ability to orchestrate an unforgettable party at Wayne Manor. 🎭\n",
    "\n",
    "# With these integrations, Alfred can tap into advanced event-planning tools—whether it’s adjusting \n",
    "# the lighting for the perfect ambiance, curating the ideal playlist for the party, or coordinating with Gotham’s finest caterers.\n",
    "\n",
    "# Sharing a Tool to the Hub\n",
    "# Sharing your custom tool with the community is easy! Simply upload it to your Hugging Face account using the push_to_hub() method.\n",
    "# For instance, Alfred can share his party_theme_tool to help others find the best catering services in Gotham. Here’s how to do it:\n",
    "party_theme_tool.push_to_hub(\"{your_username}/party_theme_tool\", token=\"<YOUR_HUGGINGFACEHUB_API_TOKEN>\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importing a Tool from the Hub\n",
    "# You can easily import tools created by other users using the load_tool() function. \n",
    "# For example, Alfred might want to generate a promotional image for the party using AI. \n",
    "# Instead of building a tool from scratch, he can leverage a predefined one from the community:\n",
    "from smolagents import load_tool, CodeAgent, InferenceClientModel\n",
    "\n",
    "image_generation_tool = load_tool(\n",
    "    \"m-ric/text-to-image\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[image_generation_tool],\n",
    "    model=InferenceClientModel()\n",
    ")\n",
    "\n",
    "agent.run(\"Generate an image of a luxurious superhero-themed party at Wayne Manor with made-up superheros.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importing a Hugging Face Space as a Tool\n",
    "# You can also import a HF Space as a tool using Tool.from_space(). This opens up \n",
    "# possibilities for integrating with thousands of spaces from the community for tasks \n",
    "# from image generation to data analysis.\n",
    "\n",
    "# The tool will connect with the spaces Gradio backend using the gradio_client, \n",
    "# so make sure to install it via pip if you don’t have it already.\n",
    "\n",
    "# For the party, Alfred can use an existing HF Space for the generation of the AI-generated \n",
    "# image to be used in the announcement (instead of the pre-built tool we mentioned before). Let’s build it!\n",
    "from smolagents import CodeAgent, InferenceClientModel, Tool\n",
    "\n",
    "image_generation_tool = Tool.from_space(\n",
    "    \"black-forest-labs/FLUX.1-schnell\",\n",
    "    name=\"image_generator\",\n",
    "    description=\"Generate an image from a prompt\"\n",
    ")\n",
    "\n",
    "model = InferenceClientModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "\n",
    "agent = CodeAgent(tools=[image_generation_tool], model=model)\n",
    "\n",
    "agent.run(\n",
    "    \"Improve this prompt, then generate an image of it.\",\n",
    "    additional_args={'user_prompt': 'A grand superhero-themed party at Wayne Manor, with Alfred overseeing a luxurious gala'}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importing a LangChain Tool\n",
    "# We can reuse LangChain tools in your smolagents workflow!\n",
    "# You can easily load LangChain tools using the Tool.from_langchain() method. Alfred \n",
    "# is preparing for a spectacular superhero night at Wayne Manor while the Waynes are away. \n",
    "# To make sure every detail exceeds expectations, he taps into LangChain tools to find top-tier entertainment ideas.\n",
    "\n",
    "# By using Tool.from_langchain(), Alfred effortlessly adds advanced search functionalities to his smolagent, \n",
    "# enabling him to discover exclusive party ideas and services with just a few commands.\n",
    "\n",
    "# Here’s how he does it:\n",
    "from langchain.agents import load_tools\n",
    "from smolagents import CodeAgent, InferenceClientModel, Tool\n",
    "\n",
    "search_tool = Tool.from_langchain(load_tools([\"serpapi\"])[0])\n",
    "\n",
    "agent = CodeAgent(tools=[search_tool], model=model)\n",
    "\n",
    "agent.run(\"Search for luxury entertainment ideas for a superhero-themed event, such as live performances and interactive experiences.\")\n",
    "\n",
    "\n",
    "\n",
    "# Importing a tool collection from any MCP server\n",
    "# smolagents also allows importing tools from the hundreds of MCP servers available on glama.ai or smithery.ai. If you want to dive deeper about MCP, you can check our free MCP Course.\n",
    "# -Install mcp client\n",
    "# --We first need to install the mcp integration for smolagents.\n",
    "# --pip install \"smolagents[mcp]\"\n",
    "\n",
    "# The MCP servers tools can be loaded in a ToolCollection object as follow:\n",
    "\n",
    "import os\n",
    "from smolagents import ToolCollection, CodeAgent\n",
    "from mcp import StdioServerParameters\n",
    "from smolagents import InferenceClientModel\n",
    "\n",
    "\n",
    "model = InferenceClientModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "\n",
    "\n",
    "server_parameters = StdioServerParameters(\n",
    "    command=\"uvx\",\n",
    "    args=[\"--quiet\", \"pubmedmcp@0.1.3\"],\n",
    "    env={\"UV_PYTHON\": \"3.12\", **os.environ},\n",
    ")\n",
    "\n",
    "with ToolCollection.from_mcp(server_parameters, trust_remote_code=True) as tool_collection:\n",
    "    agent = CodeAgent(tools=[*tool_collection.tools], model=model, add_base_tools=True)\n",
    "    agent.run(\"Please find a remedy for hangover.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8a81c-9e77-4434-9c91-9270d276ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Building Agentic RAG Systems\n",
    "\n",
    "\n",
    "# Retrieval Augmented Generation (RAG) systems combine the capabilities of data retrieval and \n",
    "# generation models to provide context-aware responses. For example, a user’s query is passed \n",
    "# to a search engine, and the retrieved results are given to the model along with the query. \n",
    "# The model then generates a response based on the query and retrieved information.\n",
    "\n",
    "# Agentic RAG (Retrieval-Augmented Generation) extends traditional RAG systems by combining \n",
    "# autonomous agents with dynamic knowledge retrieval.\n",
    "\n",
    "# While traditional RAG systems use an LLM to answer queries based on retrieved data, agentic \n",
    "# RAG enables intelligent control of both retrieval and generation processes, improving efficiency and accuracy.\n",
    "\n",
    "# Traditional RAG systems face key limitations, such as relying on a single retrieval step and \n",
    "# focusing on direct semantic similarity with the user’s query, which may overlook relevant information.\n",
    "\n",
    "# Agentic RAG addresses these issues by allowing the agent to autonomously formulate search queries, \n",
    "# critique retrieved results, and conduct multiple retrieval steps for a more tailored and comprehensive output.\n",
    "\n",
    "\n",
    "# Custom Knowledge Base Tool\n",
    "# For specialized tasks, a custom knowledge base can be invaluable. Let’s create a tool that queries a \n",
    "# vector database of technical documentation or specialized knowledge. Using semantic search, the agent \n",
    "# can find the most relevant information for Alfred’s needs.\n",
    "# A vector database stores numerical representations (embeddings) of text or other data, created by machine \n",
    "# learning models. It enables semantic search by identifying similar meanings in high-dimensional space.\n",
    "# This approach combines predefined knowledge with semantic search to provide context-aware solutions for \n",
    "# event planning. With specialized knowledge access, Alfred can perfect every detail of the party.\n",
    "# In this example, we’ll create a tool that retrieves party planning ideas from a custom knowledge base. \n",
    "# We’ll use a BM25 retriever to search the knowledge base and return the top results, and \n",
    "# RecursiveCharacterTextSplitter to split the documents into smaller chunks for more efficient search.\n",
    "\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from smolagents import Tool\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from smolagents import CodeAgent, InferenceClientModel\n",
    "\n",
    "class PartyPlanningRetrieverTool(Tool):\n",
    "    name = \"party_planning_retriever\"\n",
    "    description = \"Uses semantic search to retrieve relevant party planning ideas for Alfred’s superhero-themed party at Wayne Manor.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be a query related to party planning or superhero themes.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(\n",
    "            docs, k=5  # Retrieve the top 5 documents\n",
    "        )\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "        return \"\\nRetrieved ideas:\\n\" + \"\".join(\n",
    "            [\n",
    "                f\"\\n\\n===== Idea {str(i)} =====\\n\" + doc.page_content\n",
    "                for i, doc in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Simulate a knowledge base about party planning\n",
    "party_ideas = [\n",
    "    {\"text\": \"A superhero-themed masquerade ball with luxury decor, including gold accents and velvet curtains.\", \"source\": \"Party Ideas 1\"},\n",
    "    {\"text\": \"Hire a professional DJ who can play themed music for superheroes like Batman and Wonder Woman.\", \"source\": \"Entertainment Ideas\"},\n",
    "    {\"text\": \"For catering, serve dishes named after superheroes, like 'The Hulk's Green Smoothie' and 'Iron Man's Power Steak.'\", \"source\": \"Catering Ideas\"},\n",
    "    {\"text\": \"Decorate with iconic superhero logos and projections of Gotham and other superhero cities around the venue.\", \"source\": \"Decoration Ideas\"},\n",
    "    {\"text\": \"Interactive experiences with VR where guests can engage in superhero simulations or compete in themed games.\", \"source\": \"Entertainment Ideas\"}\n",
    "]\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
    "    for doc in party_ideas\n",
    "]\n",
    "\n",
    "# Split the documents into smaller chunks for more efficient search\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "docs_processed = text_splitter.split_documents(source_docs)\n",
    "\n",
    "# Create the retriever tool\n",
    "party_planning_retriever = PartyPlanningRetrieverTool(docs_processed)\n",
    "\n",
    "# Initialize the agent\n",
    "agent = CodeAgent(tools=[party_planning_retriever], model=InferenceClientModel())\n",
    "\n",
    "# Example usage\n",
    "response = agent.run(\n",
    "    \"Find ideas for a luxury superhero-themed party, including entertainment, catering, and decoration options.\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb0508-34e9-4e10-bb8b-cd97f3348939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install 'smolagents[litellm]' plotly geopandas shapely kaleido -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548d557-95ff-4c0b-be19-4bfc79bede5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Agent Systems in Action\n",
    "# A multi-agent system consists of multiple specialized agents working together under the coordination \n",
    "# of an Orchestrator Agent. This approach enables complex workflows by distributing tasks among agents with distinct roles.\n",
    "\n",
    "# For example, a Multi-Agent RAG system can integrate:\n",
    "# A Web Agent for browsing the internet.\n",
    "# A Retriever Agent for fetching information from knowledge bases.\n",
    "# An Image Generation Agent for producing visuals.\n",
    "# All of these agents operate under an orchestrator that manages task delegation and interaction.\n",
    "\n",
    "# Solving a complex task with a multi-agent hierarchy\n",
    "# You can follow the code in this notebook that you can run using Google Colab.\n",
    "# The reception is approaching! With your help, Alfred is now nearly finished with the preparations.\n",
    "# But now there’s a problem: the Batmobile has disappeared. Alfred needs to find a replacement, and find it quickly.\n",
    "# Fortunately, a few biopics have been done on Bruce Wayne’s life, so maybe Alfred could get a car left behind on one \n",
    "# of the movie sets, and re-engineer it up to modern standards, which certainly would include a full self-driving option.\n",
    "# But this could be anywhere in the filming locations around the world - which could be numerous.\n",
    "\n",
    "# So Alfred wants your help. Could you build an agent able to solve this task?\n",
    "\n",
    "# 👉 Find all Batman filming locations in the world, calculate the time to transfer via boat to there, and represent them \n",
    "# on a map, with a color varying by boat transfer time. Also represent some supercar factories with the same boat transfer time.\n",
    "\n",
    "\n",
    "\n",
    "# We first make a tool to get the cargo plane transfer time.\n",
    "import math\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from smolagents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_cargo_travel_time(\n",
    "    origin_coords: Tuple[float, float],\n",
    "    destination_coords: Tuple[float, float],\n",
    "    cruising_speed_kmh: Optional[float] = 750.0,  # Average speed for cargo planes\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the travel time for a cargo plane between two points on Earth using great-circle distance.\n",
    "\n",
    "    Args:\n",
    "        origin_coords: Tuple of (latitude, longitude) for the starting point\n",
    "        destination_coords: Tuple of (latitude, longitude) for the destination\n",
    "        cruising_speed_kmh: Optional cruising speed in km/h (defaults to 750 km/h for typical cargo planes)\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated travel time in hours\n",
    "\n",
    "    Example:\n",
    "        >>> # Chicago (41.8781° N, 87.6298° W) to Sydney (33.8688° S, 151.2093° E)\n",
    "        >>> result = calculate_cargo_travel_time((41.8781, -87.6298), (-33.8688, 151.2093))\n",
    "    \"\"\"\n",
    "\n",
    "    def to_radians(degrees: float) -> float:\n",
    "        return degrees * (math.pi / 180)\n",
    "\n",
    "    # Extract coordinates\n",
    "    lat1, lon1 = map(to_radians, origin_coords)\n",
    "    lat2, lon2 = map(to_radians, destination_coords)\n",
    "\n",
    "    # Earth's radius in kilometers\n",
    "    EARTH_RADIUS_KM = 6371.0\n",
    "\n",
    "    # Calculate great-circle distance using the haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = (\n",
    "        math.sin(dlat / 2) ** 2\n",
    "        + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    )\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    distance = EARTH_RADIUS_KM * c\n",
    "\n",
    "    # Add 10% to account for non-direct routes and air traffic controls\n",
    "    actual_distance = distance * 1.1\n",
    "\n",
    "    # Calculate flight time\n",
    "    # Add 1 hour for takeoff and landing procedures\n",
    "    flight_time = (actual_distance / cruising_speed_kmh) + 1.0\n",
    "\n",
    "    # Format the results\n",
    "    return round(flight_time, 2)\n",
    "\n",
    "\n",
    "print(calculate_cargo_travel_time((41.8781, -87.6298), (-33.8688, 151.2093)))\n",
    "\n",
    "\n",
    "# Setting up the agent\n",
    "# For the model provider, we use Together AI\n",
    "# The GoogleSearchTool uses the Serper API to search the web, so this requires either having setup env \n",
    "# variable SERPAPI_API_KEY and passing provider=\"serpapi\" or having SERPER_API_KEY and passing provider=serper.\n",
    "# If you don’t have any Serp API provider setup, you can use DuckDuckGoSearchTool but beware that it has a rate limit.\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from smolagents import CodeAgent, GoogleSearchTool, InferenceClientModel, VisitWebpageTool, DuckDuckGoSearchTool\n",
    "\n",
    "model = InferenceClientModel(model_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"together\")\n",
    "\n",
    "# We can start by creating a simple agent as a baseline to give us a simple report.\n",
    "task = \"\"\"Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128° N, 74.0060° W), and return them to me as a pandas dataframe.\n",
    "Also give me some supercar factories with the same cargo plane transfer time.\"\"\"\n",
    "\n",
    "agent = CodeAgent(\n",
    "    model=model,\n",
    "    # tools=[GoogleSearchTool(\"serper\"), VisitWebpageTool(), calculate_cargo_travel_time],\n",
    "    tools=[DuckDuckGoSearchTool(), VisitWebpageTool(), calculate_cargo_travel_time],\n",
    "    additional_authorized_imports=[\"pandas\"],\n",
    "    max_steps=20,\n",
    ")\n",
    "\n",
    "result = agent.run(task)\n",
    "\n",
    "result\n",
    "\n",
    "\n",
    "\n",
    "# We could already improve this a bit by throwing in some dedicated planning steps, and adding more prompting.\n",
    "# Planning steps allow the agent to think ahead and plan its next steps, which can be useful for more complex tasks.\n",
    "agent.planning_interval = 4\n",
    "\n",
    "detailed_report = agent.run(f\"\"\"\n",
    "You're an expert analyst. You make comprehensive reports after visiting many websites.\n",
    "Don't hesitate to search for many queries at once in a for loop.\n",
    "For each data point that you find, visit the source url to confirm numbers.\n",
    "\n",
    "{task}\n",
    "\"\"\")\n",
    "\n",
    "print(detailed_report)\n",
    "\n",
    "detailed_report\n",
    "\n",
    "\n",
    "# Thanks to these quick changes, we obtained a much more concise report by simply providing our agent a detailed prompt,\n",
    "# and giving it planning capabilities!\n",
    "# The model’s context window is quickly filling up. So if we ask our agent to combine the results of detailed search with \n",
    "# another, it will be slower and quickly ramp up tokens and costs.\n",
    "# ➡️ We need to improve the structure of our system.\n",
    "\n",
    "# ✌️ Splitting the task between two agents\n",
    "# Multi-agent structures allow to separate memories between different sub-tasks, with two great benefits:\n",
    "\n",
    "# Each agent is more focused on its core task, thus more performant\n",
    "# Separating memories reduces the count of input tokens at each step, thus reducing latency and cost.\n",
    "# Let’s create a team with a dedicated web search agent, managed by another agent.\n",
    "\n",
    "# The manager agent should have plotting capabilities to write its final report: so let us give it access to additional \n",
    "# imports, including plotly, and geopandas + shapely for spatial plotting.\n",
    "model = InferenceClientModel(\n",
    "    \"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"together\", max_tokens=8096\n",
    ")\n",
    "\n",
    "web_agent = CodeAgent(\n",
    "    model=model,\n",
    "    tools=[\n",
    "        GoogleSearchTool(provider=\"serper\"),\n",
    "        VisitWebpageTool(),\n",
    "        calculate_cargo_travel_time,\n",
    "    ],\n",
    "    name=\"web_agent\",\n",
    "    description=\"Browses the web to find information\",\n",
    "    verbosity_level=0,\n",
    "    max_steps=10,\n",
    ")\n",
    "\n",
    "# The manager agent will need to do some mental heavy lifting.\n",
    "# So we give it the stronger model DeepSeek-R1, and add a planning_interval to the mix.\n",
    "from smolagents.utils import encode_image_base64, make_image_url\n",
    "from smolagents import OpenAIServerModel\n",
    "\n",
    "\n",
    "def check_reasoning_and_plot(final_answer, agent_memory):\n",
    "    multimodal_model = OpenAIServerModel(\"gpt-4o\", max_tokens=8096)\n",
    "    filepath = \"saved_map.png\"\n",
    "    assert os.path.exists(filepath), \"Make sure to save the plot under saved_map.png!\"\n",
    "    image = Image.open(filepath)\n",
    "    prompt = (\n",
    "        f\"Here is a user-given task and the agent steps: {agent_memory.get_succinct_steps()}. Now here is the plot that was made.\"\n",
    "        \"Please check that the reasoning process and plot are correct: do they correctly answer the given task?\"\n",
    "        \"First list reasons why yes/no, then write your final decision: PASS in caps lock if it is satisfactory, FAIL if it is not.\"\n",
    "        \"Don't be harsh: if the plot mostly solves the task, it should pass.\"\n",
    "        \"To pass, a plot should be made using px.scatter_map and not any other method (scatter_map looks nicer).\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": make_image_url(encode_image_base64(image))},\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    output = multimodal_model(messages).content\n",
    "    print(\"Feedback: \", output)\n",
    "    if \"FAIL\" in output:\n",
    "        raise Exception(output)\n",
    "    return True\n",
    "\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    model=InferenceClientModel(\"deepseek-ai/DeepSeek-R1\", provider=\"together\", max_tokens=8096),\n",
    "    tools=[calculate_cargo_travel_time],\n",
    "    managed_agents=[web_agent],\n",
    "    additional_authorized_imports=[\n",
    "        \"geopandas\",\n",
    "        \"plotly\",\n",
    "        \"shapely\",\n",
    "        \"json\",\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "    ],\n",
    "    planning_interval=5,\n",
    "    verbosity_level=2,\n",
    "    final_answer_checks=[check_reasoning_and_plot],\n",
    "    max_steps=15,\n",
    ")\n",
    "\n",
    "\n",
    "manager_agent.visualize()\n",
    "\n",
    "\n",
    "manager_agent.run(\"\"\"\n",
    "Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128° N, 74.0060° W).\n",
    "Also give me some supercar factories with the same cargo plane transfer time. You need at least 6 points in total.\n",
    "Represent this as spatial map of the world, with the locations represented as scatter points with a color that depends on the travel time, and save it to saved_map.png!\n",
    "\n",
    "Here's an example of how to plot and return a map:\n",
    "import plotly.express as px\n",
    "df = px.data.carshare()\n",
    "fig = px.scatter_map(df, lat=\"centroid_lat\", lon=\"centroid_lon\", text=\"name\", color=\"peak_hour\", size=100,\n",
    "     color_continuous_scale=px.colors.sequential.Magma, size_max=15, zoom=1)\n",
    "fig.show()\n",
    "fig.write_image(\"saved_image.png\")\n",
    "final_answer(fig)\n",
    "\n",
    "Never try to process strings using code: when you have a string to read, just print it and you'll see it.\n",
    "\"\"\")\n",
    "\n",
    "manager_agent.python_executor.state[\"fig\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93543de3-1e39-43d5-8380-8aae913efe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install helium selenium python-dotenv #\"smolagents[all]\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f0bfc2-34b7-41d7-9b80-427cf08bac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision Agents with smolagents\n",
    "# In this example, imagine Alfred, the butler at Wayne Manor, is tasked with verifying the identities of the \n",
    "# guests attending the party. As you can imagine, Alfred may not be familiar with everyone arriving. To help \n",
    "# him, we can use an agent that verifies their identity by searching for visual information about their appearance \n",
    "# using a VLM. This will allow Alfred to make informed decisions about who can enter. \n",
    "\n",
    "\n",
    "# Providing Images at the Start of the Agent’s Execution\n",
    "# In this approach, images are passed to the agent at the start and stored as task_images alongside the task \n",
    "# prompt. The agent then processes these images throughout its execution.\n",
    "# Consider the case where Alfred wants to verify the identities of the superheroes attending the party. He already\n",
    "# has a dataset of images from previous parties with the names of the guests. Given a new visitor’s image, the agent \n",
    "# can compare it with the existing dataset and make a decision about letting them in.\n",
    "# In this case, a guest is trying to enter, and Alfred suspects that this visitor might be The Joker impersonating \n",
    "# Wonder Woman. Alfred needs to verify their identity to prevent anyone unwanted from entering.\n",
    "# Let’s build the example. First, the images are loaded. In this case, we use images from Wikipedia to keep the \n",
    "# example minimal, but imagine the possible use-case!\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "image_urls = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/e/e8/The_Joker_at_Wax_Museum_Plus.jpg\", # Joker image\n",
    "    \"https://upload.wikimedia.org/wikipedia/en/9/98/Joker_%28DC_Comics_character%29.jpg\" # Joker image\n",
    "]\n",
    "\n",
    "images = []\n",
    "for url in image_urls:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\" \n",
    "    }\n",
    "    response = requests.get(url,headers=headers)\n",
    "    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "# Now that we have the images, the agent will tell us whether one guest is actually a superhero (Wonder Woman) or a villain (The Joker).\n",
    "from smolagents import CodeAgent, OpenAIServerModel\n",
    "\n",
    "model = OpenAIServerModel(model_id=\"gpt-4o\")\n",
    "\n",
    "# Instantiate the agent\n",
    "agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    max_steps=20,\n",
    "    verbosity_level=2\n",
    ")\n",
    "\n",
    "response = agent.run(\n",
    "    \"\"\"\n",
    "    Describe the costume and makeup that the comic character in these photos is wearing and return the description.\n",
    "    Tell me if the guest is The Joker or Wonder Woman.\n",
    "    \"\"\",\n",
    "    images=images\n",
    ")\n",
    "\n",
    "\n",
    "# Providing Images with Dynamic Retrieval\n",
    "# The previous approach is valuable and has many potential use cases. However, in situations where the guest \n",
    "# is not in the database, we need to explore other ways of identifying them. One possible solution is to dynamically \n",
    "# retrieve images and information from external sources, such as browsing the web for details.\n",
    "\n",
    "# In this approach, images are dynamically added to the agent’s memory during execution. As we know, agents in \n",
    "# smolagents are based on the MultiStepAgent class, which is an abstraction of the ReAct framework. This class \n",
    "# operates in a structured cycle where various variables and knowledge are logged at different stages:\n",
    "\n",
    "# SystemPromptStep: Stores the system prompt.\n",
    "# TaskStep: Logs the user query and any provided input.\n",
    "# ActionStep: Captures logs from the agent’s actions and results.\n",
    "# This structured approach allows agents to incorporate visual information dynamically and respond adaptively \n",
    "# to evolving tasks. When browsing, the agent can take screenshots and \n",
    "# save them as observation_images in the ActionStep.\n",
    "\n",
    "# We’ll need a set of agent tools specifically designed for browsing, such as search_item_ctrl_f, go_back, and \n",
    "# close_popups. These tools allow the agent to act like a person navigating the web.\n",
    "@tool\n",
    "def search_item_ctrl_f(text: str, nth_result: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Searches for text on the current page via Ctrl + F and jumps to the nth occurrence.\n",
    "    Args:\n",
    "        text: The text to search for\n",
    "        nth_result: Which occurrence to jump to (default: 1)\n",
    "    \"\"\"\n",
    "    elements = driver.find_elements(By.XPATH, f\"//*[contains(text(), '{text}')]\")\n",
    "    if nth_result > len(elements):\n",
    "        raise Exception(f\"Match n°{nth_result} not found (only {len(elements)} matches found)\")\n",
    "    result = f\"Found {len(elements)} matches for '{text}'.\"\n",
    "    elem = elements[nth_result - 1]\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", elem)\n",
    "    result += f\"Focused on element {nth_result} of {len(elements)}\"\n",
    "    return result\n",
    "\n",
    "\n",
    "@tool\n",
    "def go_back() -> None:\n",
    "    \"\"\"Goes back to previous page.\"\"\"\n",
    "    driver.back()\n",
    "\n",
    "\n",
    "@tool\n",
    "def close_popups() -> str:\n",
    "    \"\"\"\n",
    "    Closes any visible modal or pop-up on the page. Use this to dismiss pop-up windows! This does not work on cookie consent banners.\n",
    "    \"\"\"\n",
    "    webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "\n",
    "\n",
    "# We also need functionality for saving screenshots, as this will be an essential part of what our VLM \n",
    "# agent uses to complete the task. This functionality captures the screenshot and saves it in \n",
    "# step_log.observations_images = [image.copy()], allowing the agent to store and process the images dynamically as it navigates.\n",
    "\n",
    "def save_screenshot(step_log: ActionStep, agent: CodeAgent) -> None:\n",
    "    sleep(1.0)  # Let JavaScript animations happen before taking the screenshot\n",
    "    driver = helium.get_driver()\n",
    "    current_step = step_log.step_number\n",
    "    if driver is not None:\n",
    "        for step_logs in agent.logs:  # Remove previous screenshots from logs for lean processing\n",
    "            if isinstance(step_log, ActionStep) and step_log.step_number <= current_step - 2:\n",
    "                step_logs.observations_images = None\n",
    "        png_bytes = driver.get_screenshot_as_png()\n",
    "        image = Image.open(BytesIO(png_bytes))\n",
    "        print(f\"Captured a browser screenshot: {image.size} pixels\")\n",
    "        step_log.observations_images = [image.copy()]  # Create a copy to ensure it persists, important!\n",
    "\n",
    "    # Update observations with current URL\n",
    "    url_info = f\"Current url: {driver.current_url}\"\n",
    "    step_log.observations = url_info if step_logs.observations is None else step_log.observations + \"\\n\" + url_info\n",
    "    return\n",
    "\n",
    "\n",
    "# This function is passed to the agent as step_callback, as it’s triggered at the end of each step during \n",
    "# the agent’s execution. This allows the agent to dynamically capture and store screenshots throughout its process.\n",
    "# Now, we can generate our vision agent for browsing the web, providing it with the tools we created, along with \n",
    "# the DuckDuckGoSearchTool to explore the web. This tool will help the agent retrieve necessary information for\n",
    "# verifying guests’ identities based on visual cues.\n",
    "\n",
    "from smolagents import CodeAgent, OpenAIServerModel, DuckDuckGoSearchTool\n",
    "model = OpenAIServerModel(model_id=\"gpt-4o\")\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[DuckDuckGoSearchTool(), go_back, close_popups, search_item_ctrl_f],\n",
    "    model=model,\n",
    "    additional_authorized_imports=[\"helium\"],\n",
    "    step_callbacks=[save_screenshot],\n",
    "    max_steps=20,\n",
    "    verbosity_level=2,\n",
    ")\n",
    "\n",
    "# With that, Alfred is ready to check the guests’ identities and make informed decisions about whether to let them into the party:\n",
    "agent.run(\"\"\"\n",
    "I am Alfred, the butler of Wayne Manor, responsible for verifying the identity of guests at party. A superhero has arrived at the entrance claiming to be Wonder Woman, but I need to confirm if she is who she says she is.\n",
    "\n",
    "Please search for images of Wonder Woman and generate a detailed visual description based on those images. Additionally, navigate to Wikipedia to gather key details about her appearance. With this information, I can determine whether to grant her access to the event.\n",
    "\"\"\" + helium_instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208002b3-169a-4abe-ae24-5e40a1fd1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Basic Code Agent with Web Search Capability\n",
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[DuckDuckGoSearchTool()],\n",
    "    model=HfApiModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    ")\n",
    "\n",
    "\n",
    "# Set Up a Multi-Agent System with Manager and Web Search Agents\n",
    "web_agent = ToolCallingAgent(\n",
    "    tools=[DuckDuckGoSearchTool(), visit_webpage],\n",
    "    model=model,\n",
    "    max_steps=10,\n",
    "    name=\"search\",\n",
    "    description=\"Runs web searches for you.\"\n",
    ")\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    managed_agents=[web_agent],\n",
    "    additional_authorized_imports=[\"time\", \"numpy\", \"pandas\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Configure Agent Security Settings\n",
    "from smolagents import CodeAgent, E2BSandbox\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    sandbox=E2BSandbox(),\n",
    "    additional_authorized_imports=[\"numpy\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Implement a Tool-Calling Agent\n",
    "from smolagents import ToolCallingAgent\n",
    "\n",
    "agent = ToolCallingAgent(\n",
    "    tools=[custom_tool],\n",
    "    model=model,\n",
    "    max_steps=5,\n",
    "    name=\"tool_agent\",\n",
    "    description=\"Executes specific tools based on input\"\n",
    ")\n",
    "\n",
    "\n",
    "# Set Up Model Integration\n",
    "from smolagents import HfApiModel, LiteLLMModel\n",
    "\n",
    "# Hugging Face model\n",
    "hf_model = HfApiModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "\n",
    "# Alternative model via LiteLLM\n",
    "other_model = LiteLLMModel(\"anthropic/claude-3-sonnet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
